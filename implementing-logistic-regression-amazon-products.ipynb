{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":3,"outputs":[{"output_type":"stream","text":"/kaggle/input/important-words/important_words.json\n/kaggle/input/amazon-baby-subset/m_8dcbdadfd1761929.0000\n/kaggle/input/amazon-baby-subset/m_8dcbdadfd1761929.frame_idx\n/kaggle/input/amazon-baby-subset/objects.bin\n/kaggle/input/amazon-baby-subset/m_8dcbdadfd1761929.sidx\n/kaggle/input/amazon-baby-subset/dir_archive.ini\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install turicreate\nimport turicreate as tc","execution_count":4,"outputs":[{"output_type":"stream","text":"Collecting turicreate\n  Downloading turicreate-6.4-cp37-cp37m-manylinux1_x86_64.whl (92.0 MB)\n\u001b[K     |████████████████████████████████| 92.0 MB 19.4 MB/s eta 0:00:01     |████████████▋                   | 36.3 MB 12.1 MB/s eta 0:00:05     |██████████████▌                 | 41.7 MB 15.6 MB/s eta 0:00:04     |████████████████████████▌       | 70.5 MB 13.0 MB/s eta 0:00:02\n\u001b[?25hCollecting coremltools==3.3\n  Downloading coremltools-3.3-cp37-none-manylinux1_x86_64.whl (3.5 MB)\n\u001b[K     |████████████████████████████████| 3.5 MB 29.1 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from turicreate) (1.18.5)\nCollecting resampy==0.2.1\n  Downloading resampy-0.2.1.tar.gz (322 kB)\n\u001b[K     |████████████████████████████████| 322 kB 23.1 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from turicreate) (1.14.0)\nCollecting tensorflow<2.1.0,>=2.0.0\n  Downloading tensorflow-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (86.4 MB)\n\u001b[K     |████████████████████████████████| 86.4 MB 118 kB/s  eta 0:00:01     |██████████████████▉             | 50.8 MB 21.1 MB/s eta 0:00:02     |███████████████████████████     | 73.1 MB 14.1 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: pillow>=5.2.0 in /opt/conda/lib/python3.7/site-packages (from turicreate) (7.2.0)\nRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from turicreate) (1.4.1)\nRequirement already satisfied: numba<0.51.0 in /opt/conda/lib/python3.7/site-packages (from turicreate) (0.48.0)\nRequirement already satisfied: decorator>=4.0.9 in /opt/conda/lib/python3.7/site-packages (from turicreate) (4.4.2)\nRequirement already satisfied: requests>=2.9.1 in /opt/conda/lib/python3.7/site-packages (from turicreate) (2.23.0)\nRequirement already satisfied: prettytable==0.7.2 in /opt/conda/lib/python3.7/site-packages (from turicreate) (0.7.2)\nRequirement already satisfied: pandas>=0.23.2 in /opt/conda/lib/python3.7/site-packages (from turicreate) (1.1.1)\nRequirement already satisfied: protobuf>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from coremltools==3.3->turicreate) (3.13.0)\nCollecting gast==0.2.2\n  Downloading gast-0.2.2.tar.gz (10 kB)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (1.1.2)\nCollecting tensorboard<2.1.0,>=2.0.0\n  Downloading tensorboard-2.0.2-py3-none-any.whl (3.8 MB)\n\u001b[K     |████████████████████████████████| 3.8 MB 31.7 MB/s eta 0:00:01     |█████████▉                      | 1.2 MB 31.7 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (1.1.0)\nRequirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (1.31.0)\nRequirement already satisfied: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (0.2.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (3.3.0)\nCollecting tensorflow-estimator<2.1.0,>=2.0.0\n  Downloading tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449 kB)\n\u001b[K     |████████████████████████████████| 449 kB 29.1 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (1.11.2)\nCollecting keras-applications>=1.0.8\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[K     |████████████████████████████████| 50 kB 4.6 MB/s  eta 0:00:01\n\u001b[?25hCollecting astor>=0.6.0\n  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\nRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (0.34.2)\nRequirement already satisfied: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow<2.1.0,>=2.0.0->turicreate) (0.10.0)\nRequirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /opt/conda/lib/python3.7/site-packages (from numba<0.51.0->turicreate) (0.31.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from numba<0.51.0->turicreate) (46.1.3.post20200325)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.9.1->turicreate) (2.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.9.1->turicreate) (2020.6.20)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.9.1->turicreate) (1.24.3)\nRequirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.9.1->turicreate) (3.0.4)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.23.2->turicreate) (2.8.1)\nRequirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.23.2->turicreate) (2019.3)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (0.4.1)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (3.2.1)\nRequirement already satisfied: google-auth<2,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (1.14.0)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (1.0.1)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow<2.1.0,>=2.0.0->turicreate) (2.10.0)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (1.2.0)\nRequirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (4.0)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (3.1.1)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (0.2.7)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (3.0.1)\nRequirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow<2.1.0,>=2.0.0->turicreate) (0.4.8)\nBuilding wheels for collected packages: resampy, gast\n  Building wheel for resampy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for resampy: filename=resampy-0.2.1-py3-none-any.whl size=320848 sha256=95aabdd09084cf7030c519ab0161fd69f02189cae88ca099d0c3d2b1490de3be\n  Stored in directory: /root/.cache/pip/wheels/71/74/53/d5ceb7c5ee7a168c7d106041863e71ac3273f4a4677743a284\n  Building wheel for gast (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7539 sha256=65cde76aa154e227a617b53419b3aa351a84b478440689c899452e0a6ea8f726\n  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\nSuccessfully built resampy gast\nInstalling collected packages: coremltools, resampy, gast, tensorboard, tensorflow-estimator, keras-applications, astor, tensorflow, turicreate\n  Attempting uninstall: resampy\n    Found existing installation: resampy 0.2.2\n    Uninstalling resampy-0.2.2:\n","name":"stdout"},{"output_type":"stream","text":"      Successfully uninstalled resampy-0.2.2\n  Attempting uninstall: gast\n    Found existing installation: gast 0.3.3\n    Uninstalling gast-0.3.3:\n      Successfully uninstalled gast-0.3.3\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.3.0\n    Uninstalling tensorboard-2.3.0:\n      Successfully uninstalled tensorboard-2.3.0\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.3.0\n    Uninstalling tensorflow-estimator-2.3.0:\n      Successfully uninstalled tensorflow-estimator-2.3.0\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.3.0\n    Uninstalling tensorflow-2.3.0:\n      Successfully uninstalled tensorflow-2.3.0\n\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n\nWe recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n\ntensorflow-probability 0.11.0 requires gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\nlibrosa 0.8.0 requires resampy>=0.2.2, but you'll have resampy 0.2.1 which is incompatible.\u001b[0m\nSuccessfully installed astor-0.8.1 coremltools-3.3 gast-0.2.2 keras-applications-1.0.8 resampy-0.2.1 tensorboard-2.0.2 tensorflow-2.0.2 tensorflow-estimator-2.0.1 turicreate-6.4\n\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.2.3 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Load review dataset\nWe will use a subset of the Amazon product review dataset. The subset was chosen to contain similar numbers of positive and negative reviews, as the original dataset consisted primarily of positive reviews."},{"metadata":{"trusted":true},"cell_type":"code","source":"products = tc.SFrame('../input/amazon-baby-subset')\n","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"products\n","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"Columns:\n\tname\tstr\n\treview\tstr\n\trating\tfloat\n\tsentiment\tint\n\nRows: 53072\n\nData:\n+-------------------------------+-------------------------------+--------+-----------+\n|              name             |             review            | rating | sentiment |\n+-------------------------------+-------------------------------+--------+-----------+\n| Stop Pacifier Sucking with... | All of my kids have cried ... |  5.0   |     1     |\n| Nature's Lullabies Second ... | We wanted to get something... |  5.0   |     1     |\n| Nature's Lullabies Second ... | My daughter had her 1st ba... |  5.0   |     1     |\n|  Lamaze Peekaboo, I Love You  | One of baby's first and fa... |  4.0   |     1     |\n| SoftPlay Peek-A-Boo Where'... | Very cute interactive book... |  5.0   |     1     |\n|   Our Baby Girl Memory Book   | Beautiful book, I love it ... |  5.0   |     1     |\n| Hunnt&reg; Falling Flowers... | Try this out for a spring ... |  5.0   |     1     |\n| Blessed By Pope Benedict X... | very nice Divine Mercy Pen... |  5.0   |     1     |\n| Cloth Diaper Pins Stainles... | We bought the pins as my 6... |  4.0   |     1     |\n| Cloth Diaper Pins Stainles... | It has been many years sin... |  5.0   |     1     |\n+-------------------------------+-------------------------------+--------+-----------+\n[53072 rows x 4 columns]\nNote: Only the head of the SFrame is printed.\nYou can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.","text/html":"<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n    <tr>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">name</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">review</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">rating</th>\n        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">sentiment</th>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Stop Pacifier Sucking<br>without tears with ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">All of my kids have cried<br>non-stop when I tried to ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Nature&#x27;s Lullabies Second<br>Year Sticker Calendar ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">We wanted to get<br>something to keep track ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Nature&#x27;s Lullabies Second<br>Year Sticker Calendar ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">My daughter had her 1st<br>baby over a year ago. ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Lamaze Peekaboo, I Love<br>You ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">One of baby&#x27;s first and<br>favorite books, and i ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">SoftPlay Peek-A-Boo<br>Where&#x27;s Elmo A Childr ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Very cute interactive<br>book! My son loves this ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Our Baby Girl Memory Book</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Beautiful book, I love it<br>to record cherished t ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Hunnt&amp;reg; Falling<br>Flowers and Birds Kids ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Try this out for a spring<br>project !Easy ,fun and ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Blessed By Pope Benedict<br>XVI Divine Mercy Full ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">very nice Divine Mercy<br>Pendant of Jesus now on ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Cloth Diaper Pins<br>Stainless Steel ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">We bought the pins as my<br>6 year old Autistic son ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n    </tr>\n    <tr>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">Cloth Diaper Pins<br>Stainless Steel ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">It has been many years<br>since we needed diaper ...</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5.0</td>\n        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n    </tr>\n</table>\n[53072 rows x 4 columns]<br/>Note: Only the head of the SFrame is printed.<br/>You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns.\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"products['sentiment']\n","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"dtype: int\nRows: 53072\n[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ... ]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"products.head(10)['name']","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"dtype: str\nRows: 10\n[\"Stop Pacifier Sucking without tears with Thumbuddy To Love's Binky Fairy Puppet and Adorable Book\", \"Nature's Lullabies Second Year Sticker Calendar\", \"Nature's Lullabies Second Year Sticker Calendar\", 'Lamaze Peekaboo, I Love You', \"SoftPlay Peek-A-Boo Where's Elmo A Children's Book\", 'Our Baby Girl Memory Book', 'Hunnt&reg; Falling Flowers and Birds Kids Nursery Home Decor Vinyl Mural Art Wall Paper Stickers', 'Blessed By Pope Benedict XVI Divine Mercy Full Color Medal', 'Cloth Diaper Pins Stainless Steel Traditional Safety Pin (Black)', 'Cloth Diaper Pins Stainless Steel Traditional Safety Pin (Black)']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print ('# of positive reviews =', len(products[products['sentiment']==1]))\nprint ('# of negative reviews =', len(products[products['sentiment']==-1]))","execution_count":9,"outputs":[{"output_type":"stream","text":"# of positive reviews = 26579\n# of negative reviews = 26493\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"we eliminated class imbalance by choosing a subset of the data with a similar number of positive and negative reviews."},{"metadata":{},"cell_type":"markdown","source":"# Apply text cleaning on the review data\nWe will perform some simple feature cleaning using SFrames. The last assignment used all words in building bag-of-words features, but here we limit ourselves to 193 words (for simplicity). We compiled a list of 193 most frequent words into a JSON file.\n\nNow, we will load these words from this JSON file:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nwith open('../input/important-words/important_words.json', 'r') as f: # Reads the list of most frequent words\n    important_words = json.load(f)\nimportant_words = [str(s) for s in important_words]","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(important_words)","execution_count":11,"outputs":[{"output_type":"stream","text":"['baby', 'one', 'great', 'love', 'use', 'would', 'like', 'easy', 'little', 'seat', 'old', 'well', 'get', 'also', 'really', 'son', 'time', 'bought', 'product', 'good', 'daughter', 'much', 'loves', 'stroller', 'put', 'months', 'car', 'still', 'back', 'used', 'recommend', 'first', 'even', 'perfect', 'nice', 'bag', 'two', 'using', 'got', 'fit', 'around', 'diaper', 'enough', 'month', 'price', 'go', 'could', 'soft', 'since', 'buy', 'room', 'works', 'made', 'child', 'keep', 'size', 'small', 'need', 'year', 'big', 'make', 'take', 'easily', 'think', 'crib', 'clean', 'way', 'quality', 'thing', 'better', 'without', 'set', 'new', 'every', 'cute', 'best', 'bottles', 'work', 'purchased', 'right', 'lot', 'side', 'happy', 'comfortable', 'toy', 'able', 'kids', 'bit', 'night', 'long', 'fits', 'see', 'us', 'another', 'play', 'day', 'money', 'monitor', 'tried', 'thought', 'never', 'item', 'hard', 'plastic', 'however', 'disappointed', 'reviews', 'something', 'going', 'pump', 'bottle', 'cup', 'waste', 'return', 'amazon', 'different', 'top', 'want', 'problem', 'know', 'water', 'try', 'received', 'sure', 'times', 'chair', 'find', 'hold', 'gate', 'open', 'bottom', 'away', 'actually', 'cheap', 'worked', 'getting', 'ordered', 'came', 'milk', 'bad', 'part', 'worth', 'found', 'cover', 'many', 'design', 'looking', 'weeks', 'say', 'wanted', 'look', 'place', 'purchase', 'looks', 'second', 'piece', 'box', 'pretty', 'trying', 'difficult', 'together', 'though', 'give', 'started', 'anything', 'last', 'company', 'come', 'returned', 'maybe', 'took', 'broke', 'makes', 'stay', 'instead', 'idea', 'head', 'said', 'less', 'went', 'working', 'high', 'unit', 'seems', 'picture', 'completely', 'wish', 'buying', 'babies', 'won', 'tub', 'almost', 'either']\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Now, we will perform 2 simple data transformations:\n\nRemove punctuation using Python's built-in string functionality.\nCompute word counts (only for important_words)\""},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_punctuation(text):\n    import string\n    return text.translate(string.punctuation) \n\nproducts['review_clean'] = products['review'].apply(remove_punctuation)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for word in important_words:\n    products[word] = products['review_clean'].apply(lambda s : s.split().count(word))","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"products['perfect']","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"dtype: int\nRows: 53072\n[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ... ]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Convert SFrame to NumPy array"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_numpy_data(data_sframe, features, label):\n    data_sframe['intercept'] = 1\n    features = ['intercept'] + features\n    features_sframe = data_sframe[features]\n    feature_matrix = features_sframe.to_numpy()\n    label_sarray = data_sframe[label]\n    label_array = label_sarray.to_numpy()\n    return(feature_matrix, label_array)\n","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_matrix, sentiment = get_numpy_data(products, important_words, 'sentiment') ","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_matrix.shape","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"(53072, 194)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"array([ 1,  1,  1, ..., -1, -1, -1])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Estimating conditional probability with link function\n\nP(yi=+1|xi,w)=11+exp(−wTh(xi)),\nwhere the feature vector h(xi) represents the word counts of important_words in the review xi. Complete the following function that implements the link function:"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nproduces probablistic estimate for P(y_i = +1 | x_i, w).\nestimate ranges between 0 and 1.\n'''\ndef predict_probability(feature_matrix, coefficients):\n    # Take dot product of feature_matrix and coefficients  \n    # YOUR CODE HERE\n    scores = np.dot(feature_matrix, coefficients)\n    \n    # Compute P(y_i = +1 | x_i, w) using the link function\n    # YOUR CODE HERE\n    predictions = 1. / (1 + np.exp(-scores))\n    \n    # return predictions\n    return predictions","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dummy_feature_matrix = np.array([[1.,2.,3.], [1.,-1.,-1]])\ndummy_coefficients = np.array([1., 3., -1.])\n\ncorrect_scores      = np.array( [ 1.*1. + 2.*3. + 3.*(-1.),          1.*1. + (-1.)*3. + (-1.)*(-1.) ] )\ncorrect_predictions = np.array( [ 1./(1+np.exp(-correct_scores[0])), 1./(1+np.exp(-correct_scores[1])) ] )\n\nprint ('The following outputs must match ')\nprint ('------------------------------------------------')\nprint ('correct_predictions           =', correct_predictions)\nprint ('output of predict_probability =', predict_probability(dummy_feature_matrix, dummy_coefficients))","execution_count":21,"outputs":[{"output_type":"stream","text":"The following outputs must match \n------------------------------------------------\ncorrect_predictions           = [0.98201379 0.26894142]\noutput of predict_probability = [0.98201379 0.26894142]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Compute derivative of log likelihood with respect to a single coefficient\n\n∂ℓ∂wj=∑i=1Nhj(xi)(1[yi=+1]−P(yi=+1|xi,w))\nWe will now write a function that computes the derivative of log likelihood with respect to a single coefficient wj. The function accepts two arguments:\n\nerrors vector containing 1[yi=+1]−P(yi=+1|xi,w) for all i.\nfeature vector containing hj(xi) for all i."},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_log_likelihood(feature_matrix, sentiment, coefficients):\n    indicator = (sentiment==+1)\n    scores = np.dot(feature_matrix, coefficients)\n    logexp = np.log(1. + np.exp(-scores))\n    \n    # Simple check to prevent overflow\n    mask = np.isinf(logexp)\n    logexp[mask] = -scores[mask]\n    \n    lp = np.sum((indicator-1)*scores - logexp)\n    return lp","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def feature_derivative(errors, feature):     \n    # Compute the dot product of errors and feature\n    derivative = np.dot(errors, feature)\n    \n    # Return the derivative\n    return derivative","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from math import sqrt\n\ndef logistic_regression(feature_matrix, sentiment, initial_coefficients, step_size, max_iter):\n    coefficients = np.array(initial_coefficients) # make sure it's a numpy array\n    for itr in range(max_iter):\n\n        # Predict P(y_i = +1|x_i,w) using your predict_probability() function\n        # YOUR CODE HERE\n        predictions = predict_probability(feature_matrix, coefficients)\n        \n        # Compute indicator value for (y_i = +1)\n        indicator = (sentiment==+1)\n        \n        # Compute the errors as indicator - predictions\n        errors = indicator - predictions\n        for j in range(len(coefficients)): # loop over each coefficient\n            \n            # Recall that feature_matrix[:,j] is the feature column associated with coefficients[j].\n            # Compute the derivative for coefficients[j]. Save it in a variable called derivative\n            # YOUR CODE HERE\n            derivative = feature_derivative(errors, feature_matrix[:, j])\n            \n            # add the step size times the derivative to the current coefficient\n            ## YOUR CODE HERE\n            coefficients[j] += step_size * derivative\n        \n        # Checking whether log likelihood is increasing\n        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) \\\n        or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n            lp = compute_log_likelihood(feature_matrix, sentiment, coefficients)\n            print ('iteration %*d: log likelihood of observed labels = %.8f' % \\\n                (int(np.ceil(np.log10(max_iter))), itr, lp))\n    return coefficients","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coefficients = logistic_regression(feature_matrix, sentiment, initial_coefficients=np.zeros(194),\n                                   step_size=1e-7, max_iter=301)","execution_count":38,"outputs":[{"output_type":"stream","text":"iteration   0: log likelihood of observed labels = -36782.24149905\niteration   1: log likelihood of observed labels = -36777.77993493\niteration   2: log likelihood of observed labels = -36773.32246359\niteration   3: log likelihood of observed labels = -36768.86907436\niteration   4: log likelihood of observed labels = -36764.41975666\niteration   5: log likelihood of observed labels = -36759.97449997\niteration   6: log likelihood of observed labels = -36755.53329383\niteration   7: log likelihood of observed labels = -36751.09612785\niteration   8: log likelihood of observed labels = -36746.66299174\niteration   9: log likelihood of observed labels = -36742.23387522\niteration  10: log likelihood of observed labels = -36737.80876812\niteration  11: log likelihood of observed labels = -36733.38766031\niteration  12: log likelihood of observed labels = -36728.97054176\niteration  13: log likelihood of observed labels = -36724.55740245\niteration  14: log likelihood of observed labels = -36720.14823248\niteration  15: log likelihood of observed labels = -36715.74302197\niteration  20: log likelihood of observed labels = -36693.77602065\niteration  30: log likelihood of observed labels = -36650.13348177\niteration  40: log likelihood of observed labels = -36606.87197329\niteration  50: log likelihood of observed labels = -36563.98286427\niteration  60: log likelihood of observed labels = -36521.45802595\niteration  70: log likelihood of observed labels = -36479.28979071\niteration  80: log likelihood of observed labels = -36437.47091460\niteration  90: log likelihood of observed labels = -36395.99454329\niteration 100: log likelihood of observed labels = -36354.85418097\niteration 200: log likelihood of observed labels = -35960.70841629\niteration 300: log likelihood of observed labels = -35594.84598974\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Predicting sentiments\nNow, we will write some code to compute class predictions. We will do this in two steps:\n\nStep 1: First compute the scores using feature_matrix and coefficients using a dot product.\nStep 2: Using the formula above, compute the class predictions from the scores.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = np.dot(feature_matrix, coefficients)","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_predictions = np.array(tc.SArray(scores).apply(lambda x: 1 if x> 0 else -1))\nprint (class_predictions)","execution_count":41,"outputs":[{"output_type":"stream","text":"[ 1 -1  1 ... -1 -1 -1]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique, counts = np.unique(class_predictions, return_counts=True)\nprint (unique, counts)","execution_count":43,"outputs":[{"output_type":"stream","text":"[-1  1] [28358 24714]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(sentiment)","execution_count":44,"outputs":[{"output_type":"execute_result","execution_count":44,"data":{"text/plain":"53072"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Measuring accuracy\nWe will now measure the classification accuracy of the model. Recall from the lecture that the classification accuracy can be computed as follows:\n\naccuracy=# correctly classified data points# total data points\nComplete the following code block to compute the accuracy of the mode"},{"metadata":{"trusted":true},"cell_type":"code","source":"num_mistakes = (class_predictions != sentiment).sum() # YOUR CODE HERE\nnum_correct = len(sentiment) - num_mistakes\naccuracy = num_correct/float(len(sentiment)) # YOUR CODE HERE\n\nprint('# Reviews   correctly classified =', len(products) - num_mistakes)\nprint('# Reviews incorrectly classified =', num_mistakes)\nprint('# Reviews total                  =', len(products))\n\nprint('Accuracy = %.2f' % accuracy)","execution_count":51,"outputs":[{"output_type":"stream","text":"# Reviews   correctly classified = 39117\n# Reviews incorrectly classified = 13955\n# Reviews total                  = 53072\nAccuracy = 0.74\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Most positive and negative words\nTreat each coefficient as a tuple, i.e. (word, coefficient_value).\nSort all the (word, coefficient_value) tuples by coefficient_value in descending order.\""},{"metadata":{"trusted":true},"cell_type":"code","source":"coefficients = list(coefficients[1:]) # exclude intercept\nword_coefficient_tuples = [(word, coefficient) for word, coefficient in zip(important_words, coefficients)]\nword_coefficient_tuples = sorted(word_coefficient_tuples, key=lambda x:x[1], reverse=True)","execution_count":52,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_coefficient_tuples[0:5]","execution_count":53,"outputs":[{"output_type":"execute_result","execution_count":53,"data":{"text/plain":"[('love', 0.06516288823238833),\n ('easy', 0.062029546990689),\n ('great', 0.0506832503387355),\n ('little', 0.04496421284998458),\n ('loves', 0.044877363993897273)]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Ten \"most positive\" words\nNow, we compute the 10 words that have the most positive coefficient values. These words are associated with positive sentiment."},{"metadata":{"trusted":true},"cell_type":"code","source":"word_coefficient_tuples[0:10]","execution_count":54,"outputs":[{"output_type":"execute_result","execution_count":54,"data":{"text/plain":"[('love', 0.06516288823238833),\n ('easy', 0.062029546990689),\n ('great', 0.0506832503387355),\n ('little', 0.04496421284998458),\n ('loves', 0.044877363993897273),\n ('perfect', 0.022685984298359947),\n ('well', 0.02069821773359),\n ('fits', 0.017082080870341066),\n ('nice', 0.01654065849254456),\n ('daughter', 0.016455556557297815)]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Ten \"most negative\" words\nNext, we repeat this exercise on the 10 most negative words. That is, we compute the 10 words that have the most negative coefficient values. These words are associated with negative sentiment."},{"metadata":{"trusted":true},"cell_type":"code","source":"word_coefficient_tuples[-10:]","execution_count":55,"outputs":[{"output_type":"execute_result","execution_count":55,"data":{"text/plain":"[('monitor', -0.020681811214603288),\n ('thought', -0.020756425233543412),\n ('work', -0.02094666567861414),\n ('money', -0.0223526167156249),\n ('waste', -0.02315534512199584),\n ('return', -0.024570662566524983),\n ('get', -0.029323997277670655),\n ('even', -0.030214144320453024),\n ('product', -0.03617625947473382),\n ('would', -0.05387975854478429)]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":4}